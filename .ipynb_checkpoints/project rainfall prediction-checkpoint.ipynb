{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBDIVISION</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUN</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AUG</th>\n",
       "      <th>SEP</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DEC</th>\n",
       "      <th>ANNUAL</th>\n",
       "      <th>Jan-Feb</th>\n",
       "      <th>Mar-May</th>\n",
       "      <th>Jun-Sep</th>\n",
       "      <th>Oct-Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4116</td>\n",
       "      <td>4116.000000</td>\n",
       "      <td>4112.000000</td>\n",
       "      <td>4113.000000</td>\n",
       "      <td>4110.000000</td>\n",
       "      <td>4112.000000</td>\n",
       "      <td>4113.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4109.000000</td>\n",
       "      <td>4112.000000</td>\n",
       "      <td>4110.000000</td>\n",
       "      <td>4109.000000</td>\n",
       "      <td>4105.000000</td>\n",
       "      <td>4106.000000</td>\n",
       "      <td>4090.000000</td>\n",
       "      <td>4110.000000</td>\n",
       "      <td>4107.000000</td>\n",
       "      <td>4106.000000</td>\n",
       "      <td>4103.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>BIHAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958.218659</td>\n",
       "      <td>18.957320</td>\n",
       "      <td>21.805325</td>\n",
       "      <td>27.359197</td>\n",
       "      <td>43.127432</td>\n",
       "      <td>85.745417</td>\n",
       "      <td>230.234444</td>\n",
       "      <td>347.214334</td>\n",
       "      <td>290.263497</td>\n",
       "      <td>197.361922</td>\n",
       "      <td>95.507009</td>\n",
       "      <td>39.866163</td>\n",
       "      <td>18.870580</td>\n",
       "      <td>1411.008900</td>\n",
       "      <td>40.747786</td>\n",
       "      <td>155.901753</td>\n",
       "      <td>1064.724769</td>\n",
       "      <td>154.100487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.140898</td>\n",
       "      <td>33.585371</td>\n",
       "      <td>35.909488</td>\n",
       "      <td>46.959424</td>\n",
       "      <td>67.831168</td>\n",
       "      <td>123.234904</td>\n",
       "      <td>234.710758</td>\n",
       "      <td>269.539667</td>\n",
       "      <td>188.770477</td>\n",
       "      <td>135.408345</td>\n",
       "      <td>99.519134</td>\n",
       "      <td>68.685410</td>\n",
       "      <td>42.369611</td>\n",
       "      <td>903.846565</td>\n",
       "      <td>59.308277</td>\n",
       "      <td>201.316965</td>\n",
       "      <td>707.741531</td>\n",
       "      <td>166.942660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1901.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>70.350000</td>\n",
       "      <td>175.600000</td>\n",
       "      <td>155.975000</td>\n",
       "      <td>100.525000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>804.500000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>24.050000</td>\n",
       "      <td>573.850000</td>\n",
       "      <td>34.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>138.700000</td>\n",
       "      <td>284.800000</td>\n",
       "      <td>259.400000</td>\n",
       "      <td>173.900000</td>\n",
       "      <td>65.200000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1121.300000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>74.800000</td>\n",
       "      <td>881.100000</td>\n",
       "      <td>98.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>49.950000</td>\n",
       "      <td>97.200000</td>\n",
       "      <td>305.150000</td>\n",
       "      <td>418.400000</td>\n",
       "      <td>377.800000</td>\n",
       "      <td>265.800000</td>\n",
       "      <td>148.400000</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>1644.775000</td>\n",
       "      <td>50.375000</td>\n",
       "      <td>196.950000</td>\n",
       "      <td>1288.175000</td>\n",
       "      <td>213.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>583.700000</td>\n",
       "      <td>403.500000</td>\n",
       "      <td>605.600000</td>\n",
       "      <td>595.100000</td>\n",
       "      <td>1168.600000</td>\n",
       "      <td>1609.900000</td>\n",
       "      <td>2362.800000</td>\n",
       "      <td>1664.600000</td>\n",
       "      <td>1222.000000</td>\n",
       "      <td>948.300000</td>\n",
       "      <td>648.900000</td>\n",
       "      <td>617.500000</td>\n",
       "      <td>6331.100000</td>\n",
       "      <td>699.500000</td>\n",
       "      <td>1745.800000</td>\n",
       "      <td>4536.900000</td>\n",
       "      <td>1252.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBDIVISION         YEAR          JAN          FEB          MAR  \\\n",
       "count         4116  4116.000000  4112.000000  4113.000000  4110.000000   \n",
       "unique          36          NaN          NaN          NaN          NaN   \n",
       "top          BIHAR          NaN          NaN          NaN          NaN   \n",
       "freq           115          NaN          NaN          NaN          NaN   \n",
       "mean           NaN  1958.218659    18.957320    21.805325    27.359197   \n",
       "std            NaN    33.140898    33.585371    35.909488    46.959424   \n",
       "min            NaN  1901.000000     0.000000     0.000000     0.000000   \n",
       "25%            NaN  1930.000000     0.600000     0.600000     1.000000   \n",
       "50%            NaN  1958.000000     6.000000     6.700000     7.800000   \n",
       "75%            NaN  1987.000000    22.200000    26.800000    31.300000   \n",
       "max            NaN  2015.000000   583.700000   403.500000   605.600000   \n",
       "\n",
       "                APR          MAY          JUN          JUL          AUG  \\\n",
       "count   4112.000000  4113.000000  4111.000000  4109.000000  4112.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      43.127432    85.745417   230.234444   347.214334   290.263497   \n",
       "std       67.831168   123.234904   234.710758   269.539667   188.770477   \n",
       "min        0.000000     0.000000     0.400000     0.000000     0.000000   \n",
       "25%        3.000000     8.600000    70.350000   175.600000   155.975000   \n",
       "50%       15.700000    36.600000   138.700000   284.800000   259.400000   \n",
       "75%       49.950000    97.200000   305.150000   418.400000   377.800000   \n",
       "max      595.100000  1168.600000  1609.900000  2362.800000  1664.600000   \n",
       "\n",
       "                SEP          OCT          NOV          DEC       ANNUAL  \\\n",
       "count   4110.000000  4109.000000  4105.000000  4106.000000  4090.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean     197.361922    95.507009    39.866163    18.870580  1411.008900   \n",
       "std      135.408345    99.519134    68.685410    42.369611   903.846565   \n",
       "min        0.100000     0.000000     0.000000     0.000000    62.300000   \n",
       "25%      100.525000    14.600000     0.700000     0.100000   804.500000   \n",
       "50%      173.900000    65.200000     9.500000     3.000000  1121.300000   \n",
       "75%      265.800000   148.400000    46.100000    17.500000  1644.775000   \n",
       "max     1222.000000   948.300000   648.900000   617.500000  6331.100000   \n",
       "\n",
       "            Jan-Feb      Mar-May      Jun-Sep      Oct-Dec  \n",
       "count   4110.000000  4107.000000  4106.000000  4103.000000  \n",
       "unique          NaN          NaN          NaN          NaN  \n",
       "top             NaN          NaN          NaN          NaN  \n",
       "freq            NaN          NaN          NaN          NaN  \n",
       "mean      40.747786   155.901753  1064.724769   154.100487  \n",
       "std       59.308277   201.316965   707.741531   166.942660  \n",
       "min        0.000000     0.000000    57.400000     0.000000  \n",
       "25%        4.100000    24.050000   573.850000    34.200000  \n",
       "50%       19.200000    74.800000   881.100000    98.200000  \n",
       "75%       50.375000   196.950000  1288.175000   213.500000  \n",
       "max      699.500000  1745.800000  4536.900000  1252.500000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the data set\n",
    "raw_data =pd.read_csv(r'rainfall in india 1901-2015.csv') \n",
    "\n",
    "#again using pandas inbuilt function \"descirbe\" to check if they are any missing values in the data \n",
    "raw_data.describe(include='all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `describe` not found.\n"
     ]
    }
   ],
   "source": [
    ".describe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isnull() gives us the sum of the missing values in the dataset\n",
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all the missing values as they are less than 5% of the total data.\n",
    "data_cleaned = raw_data.dropna(axis=0)\n",
    "\n",
    "#now checking the cleaned data \n",
    "data_cleaned.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#collecting names of the all the states in the dataset using the unique function in the pandas\n",
    "\n",
    "x_names=data_cleaned.SUBDIVISION.unique()\n",
    "\n",
    "np.where(x_names=='EAST UTTAR PRADESH')\n",
    "x_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Average Rainfall of Every State from 1901-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now i have created a loop in which i have subsetted the data according to unique names i found out in the subdivision section.\n",
    "#and i have plotted the annual rainfall from the year (1901-2015) for each state.\n",
    "for i in range(0,36):\n",
    "  subset_data = data_cleaned[data_cleaned.SUBDIVISION==x_names[i]]\n",
    "  plt.figure(figsize=(50,25))\n",
    "  sns.barplot(subset_data['YEAR'],subset_data['ANNUAL'])\n",
    "  plt.ylabel(x_names[i],fontsize=20)\n",
    "  plt.rcParams.update({'font.size': 22})\n",
    "  plt.xticks(rotation=90,fontsize=25)\n",
    "  plt.yticks(fontsize=25)\n",
    "  #plt.savefig('x[0].png')\n",
    "  print(x_names[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Findings\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From this analysis it is pretty clear that the states which are experiencing rapid development , their rainfall has subtainally\n",
    "#decreased in comparison to other states which are not developing so fast. There is a strong corelation between Decreasing \n",
    "#rainfall and rapid development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now i have put all the unique years in a array\n",
    "alltheyears =data_cleaned.YEAR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here i have the sorted the array using sort function. And i created a Empty pandas dataframe with columns of Statename ,\n",
    "#annual yearfall and the year corresponding to it.\n",
    "alltheyears.sort()\n",
    "df1=pd.DataFrame(columns=['SUBDIVISION','ANNUAL','YEAR'])\n",
    "alltheyears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this loop i have a excrated maximum annual rainfall from each year and put it in the empty dataframe created earlier.\n",
    "for i in range(len(alltheyears)):\n",
    " max_data =data_cleaned[data_cleaned.YEAR==alltheyears[i]]\n",
    " y=max_data.loc[max_data['ANNUAL'].idxmax()]\n",
    " new_data=y[['SUBDIVISION','ANNUAL','YEAR']]\n",
    " df=pd.DataFrame([new_data],columns=['SUBDIVISION','ANNUAL','YEAR'])\n",
    " df1=df1.append(df,ignore_index=True)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS you can see dataframe is sorted according to the years and maximum rainfall.\n",
    "df1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now basically I have plotted the maximum rainfall in india for each year.\n",
    "plt.figure(figsize=(50,25))\n",
    "pp=sns.barplot(df1['YEAR'],df1['ANNUAL'])\n",
    "#plt.ylabel(x[i],fontsize=20)\n",
    "pp.set_xlabel('YEAR')\n",
    "plt.rcParams.update({'font.size': 80})\n",
    "plt.xticks(rotation=90,fontsize=30)\n",
    "plt.yticks(fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall Predicition for Every State (Andaman and Nicobar Islands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set= data_cleaned[data_cleaned.SUBDIVISION==x_names[0]] \n",
    "req_data= data_set[['ANNUAL','YEAR']]\n",
    "x=req_data['YEAR'].values.reshape(-1,1)\n",
    "y=req_data['ANNUAL'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Split Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing train test split function which will split the into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the variables with an 80-20 split and some random state\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "model=regressor.fit(x_train,y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(model.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new=[[2020]]\n",
    "print(model.predict(x_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall Predicition for Every State (ARUNACHAL PRADESH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_1= data_cleaned[data_cleaned.SUBDIVISION==x_names[1]] \n",
    "req_data1= data_set_1[['ANNUAL','YEAR']]\n",
    "x1=req_data1['YEAR'].values.reshape(-1,1)\n",
    "y1=req_data1['ANNUAL'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Split Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the variables with an 80-20 split and some random state\n",
    "x_train1, x_test1, y_train1, y_test1= train_test_split(x1,y1, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1=regressor.fit(x_train1,y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(model1.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(model1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 =model1.predict(x_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pd.DataFrame({'Actual': y_test1.flatten(), 'Predicted': y_pred1.flatten()})\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new1 = [[2017]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.predict(x_new1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall Predicition for Every State (TAMIL NADU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_2= data_cleaned[data_cleaned.SUBDIVISION==x_names[30]] \n",
    "req_data2= data_set_2[['ANNUAL','YEAR']]\n",
    "x2=req_data2['YEAR'].values.reshape(-1,1)\n",
    "y2=req_data2['ANNUAL'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the variables with an 80-20 split and some random state\n",
    "x_train2, x_test2, y_train2, y_test2= train_test_split(x2,y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=regressor.fit(x_train2,y_train2)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(model2.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(model2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=model2.predict(x_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = pd.DataFrame({'Actual': y_test2.flatten(), 'Predicted': y_pred2.flatten()})\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new2 = [[2020]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model2.predict(x_new2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall Predicition for Every State (KERELA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_3= data_cleaned[data_cleaned.SUBDIVISION==x_names[34]] \n",
    "req_data3= data_set_3[['ANNUAL','YEAR']]\n",
    "x3=req_data3['YEAR'].values.reshape(-1,1)\n",
    "y3=req_data3['ANNUAL'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST TRAIN SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the variables with an 80-20 split and some random state\n",
    "x_train3, x_test3, y_train3, y_test3= train_test_split(x3,y3, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=regressor.fit(x_train3,y_train3)\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(model3.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(model3.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3=model3.predict(x_test3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = pd.DataFrame({'Actual': y_test3.flatten(), 'Predicted': y_pred3.flatten()})\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new3 = [[2018]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model3.predict(x_new3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall Predicition for Every State (UTTAR PRADESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_set_a= data_cleaned[data_cleaned.SUBDIVISION==x_names[9]] \n",
    "data_set_b =data_cleaned[data_cleaned.SUBDIVISION==x_names[10]] \n",
    "data_set_a=data_set_a[['ANNUAL','YEAR']].reset_index(drop=True)\n",
    "data_set_b=data_set_b[['ANNUAL']].reset_index(drop=True)\n",
    "data_set_4  = pd.concat([data_set_a,data_set_b],axis=1,ignore_index=True)\n",
    "\n",
    "data_set_4['ANNUAL']=data_set_4[0] +data_set_4[2]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4=data_set_4[1].values.reshape(-1,1)\n",
    "y4=data_set_4['ANNUAL'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the variables with an 80-20 split and some random state\n",
    "x_train4, x_test4, y_train4, y_test4= train_test_split(x4,y4, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=regressor.fit(x_train4,y_train4)\n",
    "model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(model4.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(model4.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4=model4.predict(x_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4= pd.DataFrame({'Actual': y_test4.flatten(), 'Predicted': y_pred4.flatten()})\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new4= [[2018]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model4.predict(x_new4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall Predicition for Every State (ASSAM AND MEGHLAYA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_5= data_cleaned[data_cleaned.SUBDIVISION==x_names[2]] \n",
    "req_data5= data_set_5[['ANNUAL','YEAR']]\n",
    "x5=req_data5['YEAR'].values.reshape(-1,1)\n",
    "y5=req_data5['ANNUAL'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the variables with an 80-20 split and some random state\n",
    "x_train5, x_test5, y_train5, y_test5= train_test_split(x5,y5, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=regressor.fit(x_train5,y_train5)\n",
    "model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(model5.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(model5.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5=model5.predict(x_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5= pd.DataFrame({'Actual': y_test5.flatten(), 'Predicted': y_pred5.flatten()})\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new4= [[2018]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model5.predict(x_new4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
